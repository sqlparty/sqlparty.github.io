---
layout: post
status: publish
published: true
title: Hive中文乱码(JDBC连接HiveServer2)问题解决
author:
  display_name: super
  login: super
  email: sqlparty@gmail.com
  url: ''
author_login: super
author_email: sqlparty@gmail.com
excerpt: "工作中遇到通过jdbc连接hive服务器(我们是用HiveServer2)，获取的中文是乱码的问题。使用beeline有同样的效果，而用hive命令行却能正常显示中文。而写入，读取的文件，都是用的UTF-8，Java环境也都是UTF-8字符集。这是怎么回事？\r\n<h2>问题重现<&#47;h2>\r\n我们可以以如下方式重现：\r\n\r\n<span
  style=\"color: #0000ff;\">shell> cat upload.txt<&#47;span>\r\n<span style=\"color:
  #0000ff;\">row1<&#47;span>\r\n<span style=\"color: #0000ff;\">行2<&#47;span>\r\n<span
  style=\"color: #0000ff;\">行3<&#47;span>\r\n<span style=\"color: #0000ff;\">row4<&#47;span>\r\n\r\nhive中在default库中创建表str_test(v
  string)，然后将upload.txt文件上传到该表的存储路径：\r\n\r\n<span style=\"color: #0000ff;\">shell>
  hadoop fs -put upload.txt &#47;user&#47;hive&#47;warehouse&#47;str_test&#47;<&#47;span>\r\n<span
  style=\"color: #0000ff;\">shell> beeline -d org.apache.hive.jdbc.HiveDriver -u jdbc:hive2:&#47;&#47;localhost:10000
  -e \"select * from str_test\"<&#47;span>\r\n<span style=\"color: #0000ff;\">...<&#47;span>\r\n<span
  style=\"color: #0000ff;\">+-------+<&#47;span>\r\n<span style=\"color: #0000ff;\">|
  v |<&#47;span>\r\n<span style=\"color: #0000ff;\">+-------+<&#47;span>\r\n<span
  style=\"color: #0000ff;\">| row1 |<&#47;span>\r\n<span style=\"color: #0000ff;\">|
  ?2 |<&#47;span>\r\n<span style=\"color: #0000ff;\">| ?3 |<&#47;span>\r\n<span style=\"color:
  #0000ff;\">| row4 |<&#47;span>\r\n<span style=\"color: #0000ff;\">| |<&#47;span>\r\n<span
  style=\"color: #0000ff;\">+-------+<&#47;span>\r\n\r\n<span style=\"color: #0000ff;\">shell>
  hive -e \"select * from str_test\"<&#47;span>\r\n<span style=\"color: #0000ff;\">...<&#47;span>\r\n<span
  style=\"color: #0000ff;\">row1<&#47;span>\r\n<span style=\"color: #0000ff;\">行2<&#47;span>\r\n<span
  style=\"color: #0000ff;\">行3<&#47;span>\r\n<span style=\"color: #0000ff;\">row4<&#47;span>\r\n\r\n出现乱码时，交互方式是：<strong>Client->jdbc->Hive
  Server2->Hadoop<&#47;strong>，而正常显示的Hive命令行的交互是：<strong>Hive CLI->Hadoop<&#47;strong>。所以基本可以确定乱码问题在Client->jdbc->Hive
  Server2这三个部分的其中一个部分上。\r\n\r\n"
wordpress_id: 798
wordpress_url: http://www.sqlparty.com/?p=798
date: '2013-12-08 15:48:09 +0800'
date_gmt: '2013-12-08 07:48:09 +0800'
categories:
- 大数据
tags:
- 问题集
- hive
- jdbc
---
<p>工作中遇到通过jdbc连接hive服务器(我们是用HiveServer2)，获取的中文是乱码的问题。使用beeline有同样的效果，而用hive命令行却能正常显示中文。而写入，读取的文件，都是用的UTF-8，Java环境也都是UTF-8字符集。这是怎么回事？</p>
<h2>问题重现<&#47;h2><br />
我们可以以如下方式重现：</p>
<p><span style="color: #0000ff;">shell> cat upload.txt<&#47;span><br />
<span style="color: #0000ff;">row1<&#47;span><br />
<span style="color: #0000ff;">行2<&#47;span><br />
<span style="color: #0000ff;">行3<&#47;span><br />
<span style="color: #0000ff;">row4<&#47;span></p>
<p>hive中在default库中创建表str_test(v string)，然后将upload.txt文件上传到该表的存储路径：</p>
<p><span style="color: #0000ff;">shell> hadoop fs -put upload.txt &#47;user&#47;hive&#47;warehouse&#47;str_test&#47;<&#47;span><br />
<span style="color: #0000ff;">shell> beeline -d org.apache.hive.jdbc.HiveDriver -u jdbc:hive2:&#47;&#47;localhost:10000 -e "select * from str_test"<&#47;span><br />
<span style="color: #0000ff;">...<&#47;span><br />
<span style="color: #0000ff;">+-------+<&#47;span><br />
<span style="color: #0000ff;">| v |<&#47;span><br />
<span style="color: #0000ff;">+-------+<&#47;span><br />
<span style="color: #0000ff;">| row1 |<&#47;span><br />
<span style="color: #0000ff;">| ?2 |<&#47;span><br />
<span style="color: #0000ff;">| ?3 |<&#47;span><br />
<span style="color: #0000ff;">| row4 |<&#47;span><br />
<span style="color: #0000ff;">| |<&#47;span><br />
<span style="color: #0000ff;">+-------+<&#47;span></p>
<p><span style="color: #0000ff;">shell> hive -e "select * from str_test"<&#47;span><br />
<span style="color: #0000ff;">...<&#47;span><br />
<span style="color: #0000ff;">row1<&#47;span><br />
<span style="color: #0000ff;">行2<&#47;span><br />
<span style="color: #0000ff;">行3<&#47;span><br />
<span style="color: #0000ff;">row4<&#47;span></p>
<p>出现乱码时，交互方式是：<strong>Client->jdbc->Hive Server2->Hadoop<&#47;strong>，而正常显示的Hive命令行的交互是：<strong>Hive CLI->Hadoop<&#47;strong>。所以基本可以确定乱码问题在Client->jdbc->Hive Server2这三个部分的其中一个部分上。</p>
<p><!--more--></p>
<h2>排查1.Client<&#47;h2><br />
Client是我们自行开发的Java应用，经查整个项目一直都是用的UTF-8字符集，排查Client的编码问题。</p>
<h2>排查2.jdbc<&#47;h2><br />
网上查询一番类似的问题，参考了 文章<a href="http:&#47;&#47;wocclyl.blog.163.com&#47;blog&#47;static&#47;4622350420134301120474&#47;" target="_blank">1<&#47;a>和<a href="https:&#47;&#47;issues.apache.org&#47;jira&#47;browse&#47;HIVE-2137" target="_blank">2<&#47;a>后，我们初步认为，采用网上推荐的方案，更新hive的JDBC驱动程序，将获取的字符强制硬编码使用UTF-8字符集，可以解决我们的问题。</p>
<p>我们使用的驱动包是hive-jdbc-0.10.0-cdh4.5.0.jar，可以看到里面有两个包：</p>
<p><a href="http:&#47;&#47;www.sqlparty.com&#47;wp-content&#47;uploads&#47;2013&#47;12&#47;hive-jdbc.png"><img class="alignnone size-full wp-image-799" alt="hive-jdbc" src="http:&#47;&#47;www.sqlparty.com&#47;wp-content&#47;uploads&#47;2013&#47;12&#47;hive-jdbc.png" width="300" height="564" &#47;><&#47;a></p>
<p>我们按照网上的说法，更新org.apache.hadoop.hive.jdbc.HiveResultSet，采用如下patch：</p>
<p style="padding-left: 30px;">Index: jdbc&#47;src&#47;java&#47;org&#47;apache&#47;hadoop&#47;hive&#47;jdbc&#47;HiveQueryResultSet.java<br />
===================================================================<br />
&mdash; jdbc&#47;src&#47;java&#47;org&#47;apache&#47;hadoop&#47;hive&#47;jdbc&#47;HiveQueryResultSet.java (revision 1195103)<br />
+++ jdbc&#47;src&#47;java&#47;org&#47;apache&#47;hadoop&#47;hive&#47;jdbc&#47;HiveQueryResultSet.java (working copy)<br />
@@ -153,7 +153,7 @@<br />
StructObjectInspector soi = (StructObjectInspector) serde.getObjectInspector();<br />
List fieldRefs = soi.getAllStructFieldRefs();<br />
<span style="color: #0000ff;">- Object data = serde.deserialize(new BytesWritable(rowStr.getBytes()));<&#47;span><br />
<span style="color: #0000ff;">+ Object data = serde.deserialize(new BytesWritable(rowStr.getBytes(&ldquo;UTF-8&Prime;)));<&#47;span><br />
assert row.size() == fieldRefs.size() : row.size() + &ldquo;, &rdquo; + fieldRefs.size();<br />
for (int i = 0; i < fieldRefs.size(); i++) {<&#47;p><br />
这个patch强制将获取的内容强制使用UTF-8编码解码。修改jar的方式是</p>
<ol>
<li>获取jdbc&#47;src&#47;java&#47;org&#47;apache&#47;hadoop&#47;hive&#47;jdbc&#47;HiveQueryResultSet.java的源码（通过svn:http:&#47;&#47;svn.apache.org&#47;repos&#47;asf&#47;hive&#47;trunk或者使用Maven直接download source）<&#47;li>
<li>在依赖满足的情况下编译获取class文件<&#47;li>
<li>用新生成的HiveQueryResultSet.class直接替换掉hive-jdbc jar中org.apache.hadoop.hive.jdbc包下HiveQueryResultSet.class！<&#47;li><br />
<&#47;ol><br />
按照如上方式处理后，发现<strong>依然无效<&#47;strong>。不仅如此，我们调整LOG为DEBUG（即打印出大量DEBUG日志），然后尝试各种方法：加入打印语句、修改输出内容、甚至整个删除jar中的org.apache.hadoop.hive.jdbc包等等，最终发现，Java程序调用Hive JDBC时根本没进入<span style="color: #ff9900;">org.apache.hadoop.hive.jdbc<&#47;span>中，即使删除org.apache.hadoop.hive.jdbc这个包都没影响，生效的是<span style="color: #ff00ff;">org.apache.hive.jdbc<&#47;span>包中的内容！</p>
<p>在<span style="color: #ff00ff;">org.apache.hive.jdbc<&#47;span>包中没有找到相似的serde.deserialize这样的反序列化的语句。看来网上的方案在我们这不适用。那么这两个包是什么用途，什么关系呢？</p>
<p>从<a href="https:&#47;&#47;cwiki.apache.org&#47;confluence&#47;display&#47;Hive&#47;HiveServer2+Clients" target="_blank">HiveServer2 Clients<&#47;a>中，一段话提醒了我们：</p>
<p style="padding-left: 30px;">The JDBC connection URL format has the prefix jdbc:hive2:&#47;&#47; and the Driver class is <strong>org.apache.hive.jdbc.HiveDriver<&#47;strong>. Note that this is different from the old <a href="https:&#47;&#47;cwiki.apache.org&#47;confluence&#47;display&#47;Hive&#47;HiveServer" target="_blank">HiveServer<&#47;a>.<&#47;p><br />
再看第一版本的<a href="https:&#47;&#47;cwiki.apache.org&#47;confluence&#47;display&#47;Hive&#47;HiveClient" target="_blank">HiveServer Client<&#47;a>，使用的是:</p>
<p>driverName = "<strong>org.apache.hadoop.hive.jdbc.HiveDriver<&#47;strong>";</p>
<p>看到这两个包，在比对我们疑惑的两个包，一切明朗了：</p>
<ul>
<li><span style="color: #ff9900;">org.apache.hadoop.hive.jdbc<&#47;span> 针对HiveServer1，与我们的场景无关。<&#47;li>
<li><span style="color: #ff00ff;">org.apache.hive.jdbc<&#47;span> 针对HiveServer2，我们需要关注。<&#47;li>
<li>如上网络上给出的方案针对HiveServer1，确实不适用我们的场景。<&#47;li><br />
<&#47;ul><br />
细查<span style="color: #ff00ff;">org.apache.hive.jdbc<&#47;span>的类，发现这个版本与HiveServer1的处理完全不一样了，不是使用serde，还是直接用了thrift，其中也没找到编码相关的选项。这条路走到头了。</p>
<h2>排查3.HiveServer2<&#47;h2><br />
剩下就是检查HiveServer2使用的字符集了。</p>
<p>系统层面：<br />
<span style="color: #0000ff;">shell> locale <&#47;span><br />
<span style="color: #0000ff;">LANG=zh_CN.UTF-8<&#47;span><br />
<span style="color: #0000ff;">LC_CTYPE="zh_CN.UTF-8"<&#47;span><br />
<span style="color: #0000ff;">LC_NUMERIC="zh_CN.UTF-8"<&#47;span><br />
<span style="color: #0000ff;">LC_TIME="zh_CN.UTF-8"<&#47;span><br />
<span style="color: #0000ff;">LC_COLLATE="zh_CN.UTF-8"<&#47;span><br />
<span style="color: #0000ff;">LC_MONETARY="zh_CN.UTF-8"<&#47;span><br />
<span style="color: #0000ff;">LC_MESSAGES="zh_CN.UTF-8"<&#47;span><br />
<span style="color: #0000ff;">LC_PAPER="zh_CN.UTF-8"<&#47;span><br />
<span style="color: #0000ff;">LC_NAME="zh_CN.UTF-8"<&#47;span><br />
<span style="color: #0000ff;">LC_ADDRESS="zh_CN.UTF-8"<&#47;span><br />
<span style="color: #0000ff;">LC_TELEPHONE="zh_CN.UTF-8"<&#47;span><br />
<span style="color: #0000ff;">LC_MEASUREMENT="zh_CN.UTF-8"<&#47;span><br />
<span style="color: #0000ff;">LC_IDENTIFICATION="zh_CN.UTF-8"<&#47;span><br />
<span style="color: #0000ff;">LC_ALL=<&#47;span><br />
<span style="color: #0000ff;">shell> echo $LANG<&#47;span><br />
<span style="color: #0000ff;">zh_CN.UTF-8<&#47;span></p>
<p>我们是使用CDH4.5中自带的hive-server2启动脚本启动的hiveserver2服务，看看脚本环境中字符集是怎样的。</p>
<p>&#47;etc&#47;init.d&#47;hive-server2中添加locale命令，重启后却是这样的：</p>
<p><span style="color: #0000ff;">shell> service hive-server2 restart<&#47;span><br />
<span style="color: #0000ff;">LANG=<&#47;span><br />
<span style="color: #0000ff;">LC_CTYPE="POSIX"<&#47;span><br />
<span style="color: #0000ff;">LC_NUMERIC="POSIX"<&#47;span><br />
<span style="color: #0000ff;">LC_TIME="POSIX"<&#47;span><br />
<span style="color: #0000ff;">LC_COLLATE="POSIX"<&#47;span><br />
<span style="color: #0000ff;">LC_MONETARY="POSIX"<&#47;span><br />
<span style="color: #0000ff;">LC_MESSAGES="POSIX"<&#47;span><br />
<span style="color: #0000ff;">LC_PAPER="POSIX"<&#47;span><br />
<span style="color: #0000ff;">LC_NAME="POSIX"<&#47;span><br />
<span style="color: #0000ff;">LC_ADDRESS="POSIX"<&#47;span><br />
<span style="color: #0000ff;">LC_TELEPHONE="POSIX"<&#47;span><br />
<span style="color: #0000ff;">LC_MEASUREMENT="POSIX"<&#47;span><br />
<span style="color: #0000ff;">LC_IDENTIFICATION="POSIX"<&#47;span><br />
<span style="color: #0000ff;">LC_ALL=<&#47;span><br />
<span style="color: #0000ff;">Starting Hive Server2 (hive-server2): [确定]<&#47;span><br />
<span style="color: #0000ff;">Hive Server2 is running [确定]<&#47;span></p>
<p>看来hive-server2的运行环境并没有沿用系统层面的环境，针对它进行配置：</p>
<p>在&#47;etc&#47;init.d&#47;hive-server2删除刚添加的locale，然后添加语句：<span style="color: #0000ff;">export LANG=zh_CN.UTF-8<&#47;span></p>
<p>这样确保hive-server2的启动会使用指定字符集。</p>
<p>当然，如果使用hive --service hiveserver2命令启动，只要保证环境变量LANG=zh_CN.UTF-8即可。</p>
<p>测试结果，如上设置，重启hive-server2后，乱码问题解决！</p>
<h2>小结<&#47;h2><br />
最终解决乱码问题只是添加了export LANG=zh_CN.UTF-8，确保hive-server2的运行环境使用的是UTF-8字符集，这样Client，Hive-Server和Hadoop集群都采用了UTF-8，自然不会有乱码存在了。</p>
<p>Done!</p>
<p>参考：<br />
<a href="http:&#47;&#47;wocclyl.blog.163.com&#47;blog&#47;static&#47;4622350420134301120474&#47;" target="_blank">http:&#47;&#47;wocclyl.blog.163.com&#47;blog&#47;static&#47;4622350420134301120474&#47;<&#47;a></p>
