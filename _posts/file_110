---
layout: post
status: publish
published: true
title: Hadoop Archives用法
author:
  display_name: super
  login: super
  email: sqlparty@gmail.com
  url: ''
author_login: super
author_email: sqlparty@gmail.com
excerpt: "HDFS设计用来存储大文件，其blocksize默认是64MB，其将所有块信息都存储在内存中，这样对存储的大文件能够快速的定位，以及提升文件io的效率。\r\n但是很多情况下HDFS中会存入大量的小文件，这对影响文件访问的性能，也会大量占用NameNode的内存资源。Hadoop
  Archives是官方提供的小文件归档方案。\r\n<h2>原理：<&#47;h2>\r\nHadoop Archives运行MapReduce job来并行处理输入文件，将小文件的内容合并形成少量大文件，然后再利用index文件，指出小文件在大文件中所属的坐标，以此来减少小文件的量。Hadoop
  Archives生成归档文件格式为HAR，HAR具体结构图如下：\r\n\r\n<a href=\"http:&#47;&#47;www.sqlparty.com&#47;wp-content&#47;uploads&#47;2013&#47;11&#47;har_file_layout.png\"><img
  class=\"alignnone size-full wp-image-775\" alt=\"har_file_layout\" src=\"http:&#47;&#47;www.sqlparty.com&#47;wp-content&#47;uploads&#47;2013&#47;11&#47;har_file_layout.png\"
  width=\"407\" height=\"255\" &#47;><&#47;a>\r\n\r\n本图<a href=\"http:&#47;&#47;blog.cloudera.com&#47;blog&#47;2009&#47;02&#47;the-small-files-problem&#47;\"
  target=\"_blank\">来源<&#47;a>\r\n\r\n"
wordpress_id: 774
wordpress_url: http://www.sqlparty.com/?p=774
date: '2013-11-11 14:54:25 +0800'
date_gmt: '2013-11-11 06:54:25 +0800'
categories:
- 大数据
tags:
- Hadoop
- hdfs
---
<p>HDFS设计用来存储大文件，其blocksize默认是64MB，其将所有块信息都存储在内存中，这样对存储的大文件能够快速的定位，以及提升文件io的效率。<br />
但是很多情况下HDFS中会存入大量的小文件，这对影响文件访问的性能，也会大量占用NameNode的内存资源。Hadoop Archives是官方提供的小文件归档方案。</p>
<h2>原理：<&#47;h2><br />
Hadoop Archives运行MapReduce job来并行处理输入文件，将小文件的内容合并形成少量大文件，然后再利用index文件，指出小文件在大文件中所属的坐标，以此来减少小文件的量。Hadoop Archives生成归档文件格式为HAR，HAR具体结构图如下：</p>
<p><a href="http:&#47;&#47;www.sqlparty.com&#47;wp-content&#47;uploads&#47;2013&#47;11&#47;har_file_layout.png"><img class="alignnone size-full wp-image-775" alt="har_file_layout" src="http:&#47;&#47;www.sqlparty.com&#47;wp-content&#47;uploads&#47;2013&#47;11&#47;har_file_layout.png" width="407" height="255" &#47;><&#47;a></p>
<p>本图<a href="http:&#47;&#47;blog.cloudera.com&#47;blog&#47;2009&#47;02&#47;the-small-files-problem&#47;" target="_blank">来源<&#47;a></p>
<p><!--more--></p>
<h2>用法：<&#47;h2><br />
<span style="color: #0000ff;">shell> hadoop archive<&#47;span></p>
<p><span style="color: #0000ff;">archive -archiveName NAME -p
<parent path> <src>* <dest><&#47;span></p>
<p>-archiveName指定HAR文件名，必须使用.har扩展。</p>
<p>-p 指定父路径，这样可以指定0个或多个父路径的相对路径。如 -p &#47;foo&#47;bar a&#47;b&#47;c e&#47;f&#47;g 就是指定&#47;foo&#47;bar为父目录，a&#47;b&#47;c和e&#47;f&#47;g是相对于父目录的相对路径。如果不指定<src>*部分，那么就会取
<parent path>下的所有文件，包括子目录中的文件。</p>
<p>例如有HDFS中有如下内容：</p>
<p><span style="color: #0000ff;">shell> hadoop fs -ls -h &#47;tmp&#47;carl&#47;<&#47;span></p>
<p><span style="color: #0000ff;">Found 5 items<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 1 Administrator hadoop 6 2013-11-08 15:19 &#47;tmp&#47;carl&#47;c1.txt<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 1 Administrator hadoop 6 2013-11-08 15:19 &#47;tmp&#47;carl&#47;c2.txt<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 1 Administrator hadoop 12 2013-11-08 15:19 &#47;tmp&#47;carl&#47;c3.txt<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 1 Administrator hadoop 6 2013-11-08 15:19 &#47;tmp&#47;carl&#47;c4.txt<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 1 Administrator hadoop 9 2013-11-08 15:19 &#47;tmp&#47;carl&#47;c5.txt<&#47;span></p>
<p>将&#47;tmp&#47;carl目录下的所有小文件存档到&#47;tmp&#47;files.har：</p>
<p><span style="color: #0000ff;">shell> hadoop archive -archiveName files.har -p &#47;tmp&#47;carl &#47;tmp<&#47;span></p>
<p>Hadoop Archives是在HDFS上又做了一层封装，将小文件的内容利用mapreduce合并到一个或多个内容文件，而_index来指定每个文件在合成文件中的"坐标"。</p>
<p>files.har在hdfs中作为一个目录，其内部有如下结构：</p>
<p><span style="color: #0000ff;">shell> hadoop fs -ls &#47;tmp&#47;files.har<&#47;span></p>
<p><span style="color: #0000ff;">Found 4 items<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 3 root hadoop 0 2013-11-11 10:57 &#47;tmp&#47;files.har&#47;_SUCCESS<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 5 root hadoop 180 2013-11-11 10:57 &#47;tmp&#47;files.har&#47;_index<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 5 root hadoop 23 2013-11-11 10:57 &#47;tmp&#47;files.har&#47;_masterindex<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 3 root hadoop 39 2013-11-11 10:57 &#47;tmp&#47;files.har&#47;part-0<&#47;span></p>
<p>创建归档后，原来的数据文件不会删除，如果需要删除则手动处理。</p>
<p>要访问通过归档文件来访问原始的数据，依然可以使用hadoop fs命令，但是URI需要发生变化，采用如下：</p>
<p><span style="color: #0000ff;">har:&#47;&#47;<host>:
<port>&#47;<archive path>&#47;<file in archive><&#47;span></p>
<p>如果不指定<host>:
<port>则使用本集群的HDFS路径： har:&#47;&#47;&#47;<archive path>&#47;<file in archive></p>
<p>例如：</p>
<p>查看归档中的文件、目录信息：</p>
<p><span style="color: #0000ff;">shell> hadoop fs -ls har:&#47;&#47;&#47;tmp&#47;files.har&#47;<&#47;span><br />
<span style="color: #0000ff;">Found 5 items<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 3 root hadoop 6 2013-11-11 14:00 har:&#47;&#47;&#47;tmp&#47;files.har&#47;c1.txt<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 3 root hadoop 6 2013-11-11 14:00 har:&#47;&#47;&#47;tmp&#47;files.har&#47;c2.txt<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 3 root hadoop 12 2013-11-11 14:00 har:&#47;&#47;&#47;tmp&#47;files.har&#47;c3.txt<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 3 root hadoop 6 2013-11-11 14:00 har:&#47;&#47;&#47;tmp&#47;files.har&#47;c4.txt<&#47;span><br />
<span style="color: #0000ff;">-rw-r--r-- 3 root hadoop 9 2013-11-11 14:00 har:&#47;&#47;&#47;tmp&#47;files.har&#47;c5.txt<&#47;span></p>
<p>查看归档文件中的c1.txt的内容：</p>
<p><span style="color: #0000ff;">shell> hadoop fs -cat har:&#47;&#47;&#47;tmp&#47;files.har&#47;c1.txt<&#47;span></p>
<p>要删除整个归档，使用-rm -r :</p>
<p><span style="color: #0000ff;">shell> hadoop fs -rm -r &#47;tmp&#47;files.har<&#47;span></p>
<h2>小结：<&#47;h2><br />
利用Hadoop Archives可以方便地对小文件进行归档。其有如下注意点：</p>
<ol>
<li>其原文件不会自动删除，有需要可以自行删除<&#47;li>
<li>HAR文件的过程实际是运行一个mapreduce作业，需要hadoop集群运行此命令。实际测试发现，它不会自行Yarn框架，而是使用本地的mapred.LocalJobRunner<&#47;li>
<li>Archives一旦创建不可改变，要增加或移除里面的文件，必须重新创建归档文件<&#47;li>
<li>要归档的文件名不能有空格，可以将空格用其他符号替换(使用-Dhar.space.replacement.enable=true和-Dhar.space.replacement参数)<&#47;li>
<li>Archive暂不支持压缩功能，所以意味着空间占用不会变少<&#47;li>
<li>可以使用 har:&#47;&#47;&#47;user&#47;zoo&#47;foo.har作为mapreduce的输入，mapreduce可以访问其中所有的文件。但是由于InputFormat不会意识到这是个归档文件，也就不会有意识的将多个文件划分到单独的split中，所以依然是安装多个小文件来处理，效率依然不高<&#47;li><br />
<&#47;ol><br />
参考：</p>
<p><a href="http:&#47;&#47;hadoop.apache.org&#47;docs&#47;r1.2.1&#47;hadoop_archives.html" target="_blank">http:&#47;&#47;hadoop.apache.org&#47;docs&#47;r1.2.1&#47;hadoop_archives.html<&#47;a><br />
《Hadoop the definitive Guide》<br />
<a href="http:&#47;&#47;dongxicheng.org&#47;mapreduce&#47;hdfs-small-files-solution&#47;" target="_blank">http:&#47;&#47;dongxicheng.org&#47;mapreduce&#47;hdfs-small-files-solution&#47;<&#47;a><br />
<a href="http:&#47;&#47;blog.cloudera.com&#47;blog&#47;2009&#47;02&#47;the-small-files-problem&#47;" target="_blank">http:&#47;&#47;blog.cloudera.com&#47;blog&#47;2009&#47;02&#47;the-small-files-problem&#47;<&#47;a></p>
