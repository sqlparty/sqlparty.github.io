---
layout: post
status: publish
published: true
title: Hive远程元数据服务Thrift Metastore搭建与管理
author:
  display_name: super
  login: super
  email: sqlparty@gmail.com
  url: ''
author_login: super
author_email: sqlparty@gmail.com
excerpt: "Hive中，只有metastore组件是Hadoop没有的。metastore保存/访问Hive的表定义与分区信息。\r\n\r\n本文介绍metastore使用MySQL作为后台存储，而且创建独立服务而不是与hive客户端绑定运行在同一个JVM中。\r\n\r\n其服务的架构类似如下：\r\n\r\n<a
  href=\"http://www.sqlparty.com/wp-content/uploads/2013/09/metastore.png\"><img
  class=\"alignnone size-full wp-image-677\" alt=\"metastore\" src=\"http://www.sqlparty.com/wp-content/uploads/2013/09/metastore.png\"
  width=\"331\" height=\"387\" /></a>\r\n本图引自<a href=\"http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_18_4.html\"
  target=\"_blank\"> Cloudera</a>\r\n\r\n"
wordpress_id: 676
wordpress_url: http://www.sqlparty.com/?p=676
date: '2013-09-15 14:58:08 +0800'
date_gmt: '2013-09-15 06:58:08 +0800'
categories:
- 大数据
tags:
- hive
- thrift
- metastore
---
<p>Hive中，只有metastore组件是Hadoop没有的。metastore保存/访问Hive的表定义与分区信息。</p>
<p>本文介绍metastore使用MySQL作为后台存储，而且创建独立服务而不是与hive客户端绑定运行在同一个JVM中。</p>
<p>其服务的架构类似如下：</p>
<p><a href="http://www.sqlparty.com/wp-content/uploads/2013/09/metastore.png"><img class="alignnone size-full wp-image-677" alt="metastore" src="http://www.sqlparty.com/wp-content/uploads/2013/09/metastore.png" width="331" height="387" /></a><br />
本图引自<a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH4/4.2.0/CDH4-Installation-Guide/cdh4ig_topic_18_4.html" target="_blank"> Cloudera</a></p>
<p><!--more--></p>
<h2>一、后台数据库选择</h2><br />
Hive默认的内置Derby SQL服务器，只提供有限的、单进程的存储操作，如不能同时运行两个Hive查询。任何JDBC兼容的数据库都可以作为metastore的库，对于生产环境、Hadoop集群，推荐使用MySQL。</p>
<p><span style="color: #0000ff;">注：虽然metastore中数据量相对其后台存储的数据而言非常小，但是其是单点（Single Point of Failure），所以保证其高可用性非常重要！针对MySQL而言，可以做复制！</span></p>
<p>要将Hive的元数据保存到MySQL中，应该要有：</p>
<h3>1.适当的配置</h3><br />
分别配置jdbc url，驱动，用户名，密码，使用如下选项：</p>
<ul>
<li>javax.jdo.option.ConnectionURL</li>
<li>javax.jdo.option.ConnectionDriverName</li>
<li>javax.jdo.option.ConnectionUserName</li>
<li>javax.jdo.option.ConnectionPassword</li><br />
</ul><br />
具体含义见下文服务端配置。</p>
<h3>2.正确的表结构</h3><br />
Hive在首次连接时如果检测到数据库或表结构不存在，会自动创建，所以应赋予其合适的权限。</p>
<p style="padding-left: 30px;">关于表结构，在实践过程中遇到问题如下：<br />
我们的MySQL服务器设置是utf8/utf8_bin。这样的设置下，hive自行创建表时会报错<br />
<em>com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Specified key was too long; max key length is 767 bytes)</em><br />
<em> FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask</em><br />
经查，其执行如下SQL时报的如下错：<br />
<span style="color: #0000ff;">CREATE TABLE "TABLE_PARAMS"</span><br />
<span style="color: #0000ff;"> (</span><br />
<span style="color: #0000ff;"> "TBL_ID" BIGINT NOT NULL,</span><br />
<span style="color: #0000ff;"> "PARAM_KEY" VARCHAR(256 ) BINARY NOT NULL,</span><br />
<span style="color: #0000ff;"> "PARAM_VALUE" VARCHAR(4000 ) BINARY NULL,</span><br />
<span style="color: #0000ff;"> PRIMARY KEY ("TBL_ID" ,"PARAM_KEY" )</span><br />
<span style="color: #0000ff;"> ) ENGINE=INNODB</span><br />
MySQL中对索引的长度有限制，最大不能超过1000字节，而InnoDB引擎的索引每列最大不能超过767字节。由于MySQL的UTF8字符集中每个字符占3个字节，而这里PARAM_KEY最大长度3*256=<br />
768）超过了767的限制，所以有此报错信息。</p></p>
<p style="padding-left: 30px;">这里采取的解决方案的是：<br />
根据/usr/lib/hive/scripts/metastore/upgrade/mysql目录下的脚本信息，了解到其原生的字符集支持是latin1，所以这里手动创建数据库，指定字符集。<br />
<span style="color: #0000ff;">CREATE DATABASE metastore DEFAULT CHARACTER SET latin1</span></p><br />
也可以手动创建好所需的表:<br />
<span style="color: #0000ff;">mysql> CREATE DATABASE metastore;</span><br />
<span style="color: #0000ff;"> mysql> USE metastore;</span><br />
<span style="color: #0000ff;"> mysql> SOURCE /usr/lib/hive/scripts/metastore/upgrade/mysql/hive-schema-0.10.0.mysql.sql</span></p>
<h2>二、Metastore服务配置</h2><br />
这里搭建了Metastore作为远程服务，这样又划分了服务端/客户端两端的配置</p>
<h2>1.服务端</h2><br />
服务端的责任是接受客户端的连接响应，另与后台数据库进行交互。有如下配置项：</p>
<div>
<table class="table">
<tbody>
<tr>
<th>配置项</th></p>
<th>配置值</th></p>
<th>注释</th><br />
</tr></p>
<tr>
<td>javax.jdo.option.ConnectionURL</td></p>
<td>jdbc:mysql://<host name>/<database name>?createDatabaseIfNotExist=true</td></p>
<td>MySQL的路径</td><br />
</tr></p>
<tr>
<td>javax.jdo.option.ConnectionDriverName</td></p>
<td>com.mysql.jdbc.Driver</td></p>
<td>MySQL JDBC驱动</td><br />
</tr></p>
<tr>
<td>javax.jdo.option.ConnectionUserName</td></p>
<td><user name></td></p>
<td>MySQL用户名</td><br />
</tr></p>
<tr>
<td>javax.jdo.option.ConnectionPassword</td></p>
<td>
<password></td></p>
<td>MySQL密码</td><br />
</tr></p>
<tr>
<td>hive.metastore.warehouse.dir</td></p>
<td><base path></td></p>
<td>Hive表的默认路径，结合Hadoop的fs.defaultFS确定是存储在HDFS还是local。</td><br />
</tr></p>
<tr>
<td>datanucleus.autoStartMechanism</td></p>
<td>SchemaTable</td></p>
<td>SchemaTable选项设置DataNucleus启动时读入NUCLEUS_TABLES的内容(包括需要载入的类、相应的表、类型、版本等信息)，这些信息有助于DataNucleus进行结构的一致性检测。注：DataNucleus是Hive用来与RDBMS进行交互的组件。</td><br />
</tr><br />
</tbody><br />
</table><br />
</div><br />
示例：</p>
<property>
<name>hive.metastore.warehouse.dir</name><br />
<value>/hive</value><br />
<description>Local or HDFS directory where Hive keeps table contents, according to fs.default.name.</description><br />
</property></p>
<property>
<name>javax.jdo.option.ConnectionURL</name><br />
<value>jdbc:mysql://192.168.10.118:3306/bmmetastoredb?createDatabaseIfNotExist=true</value><br />
</property></p>
<property>
<name>javax.jdo.option.ConnectionDriverName</name><br />
<value>com.mysql.jdbc.Driver</value><br />
</property></p>
<property>
<name>javax.jdo.option.ConnectionUserName</name><br />
<value>user1</value><br />
</property></p>
<property>
<name>javax.jdo.option.ConnectionPassword</name><br />
<value>pass1</value><br />
</property><br />
<!-- datanucleus --></p>
<property>
<name>datanucleus.autoStartMechanism</name><br />
<value>SchemaTable</value><br />
</property></p>
<p>MySQL的连接驱动下载后，将mysql-connector-java-5.1.26-bin.jar置于/usr/lib/hive/lib/目录下，这样连接mysql所需要的jdbc驱动也能被找到了。</p>
<p>要配置MetaStore使用HDFS HA，则需要分配/etc/hadoop/conf下的core-site.xml和hdfs-site.xml文件。如下：<br />
<!--  core-site.xml --><!--&nbsp; core-site.xml --></p>
<property>
<name>fs.defaultFS</name><br />
<value>hdfs://myha/</value><br />
</property></p>
<p><!-- hdfs-site.xml --></p>
<property>
<name>dfs.nameservices</name><br />
<value>myha</value><br />
</property></p>
<property>
<name>dfs.ha.namenodes.myha</name><br />
<value>nn1,nn2</value><br />
</property></p>
<property>
<name>dfs.namenode.rpc-address.myha.nn1</name><br />
<value>CHBM220:8020</value><br />
</property></p>
<property>
<name>dfs.namenode.rpc-address.myha.nn2</name><br />
<value>CHBM221:8020</value><br />
</property></p>
<property>
<name>dfs.client.failover.proxy.provider.myha</name><br />
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value><br />
</property><br />
<span style="color: #0000ff;">注意：dfs.client.failover.proxy.provider.myha的配置不可或缺！</span></p>
<h2>2.客户端</h2><br />
客户端要连接到远程的Metastore服务，需要使用如下配置项。</p>
<table class="table">
<tbody>
<tr>
<th>配置项</th></p>
<th>配置值</th></p>
<th>注释</th><br />
</tr></p>
<tr>
<td>hive.metastore.uris</td></p>
<td>thrift://<host_name>:
<port></td></p>
<td>设置远程thrift metastore server的访问路径。默认端口是：9083</td><br />
</tr></p>
<tr>
<td>hive.metastore.local</td></p>
<td>false</td></p>
<td>因为使用远程metastore服务，所以这里设为false。</td><br />
</tr><br />
</tbody><br />
</table><br />
示例：</p>
<property>
<name>hive.metastore.uris</name><br />
<value>thrift://CHBM224:9083</value><br />
</property></p>
<property>
<name>hive.metastore.local</name><br />
<value>false</value><br />
</property></p>
<h2>三、Metastore管理</h2><br />
<a title="创建cdh4本地Yum仓库" href="http://www.sqlparty.com/%e5%88%9b%e5%bb%bacdh4%e6%9c%ac%e5%9c%b0yum%e4%bb%93%e5%ba%93/" target="_blank">CDH4的yum源</a>中包括了hive-metastore的管理包，安装。<br />
<span style="color: #0000ff;">shell> yum install hive-metastore</span><br />
安装后，就可以使用其管理脚本进行管理，其已经注册为服务。</p>
<h3>1.服务端启动</h3><br />
<span style="color: #0000ff;">shell> service hive-metastore start</span><br />
不指定端口的话模式使用9083端口，如果要指定端口，则在/etc/default/hive-metastore中加入：<br />
export PORT=9084<br />
启动脚本会自动读取该文件中的配置。</p>
<h3>2.服务端是否活跃</h3><br />
<span style="color: #0000ff;">shell> service hive-metastore status</span><br />
<span style="color: #0000ff;"> Hive Metastore is running [ OK ]</span></p>
<h3>3.服务端关闭</h3><br />
<span style="color: #0000ff;">shell> service hive-metastore stop</span></p>
<p>管理脚本照顾到了一些我们容易忽略的地方，使得我们操作更方便。如果不使用所安装的hive-metastore脚本进行管理，而是进行手动配置的话，可能需要考虑到如下一些情况：</p>
<p style="padding-left: 30px;">1.服务端启动<br />
Metastore服务启动，不指定端口的话模式使用9083端口：<br />
shell> sudo -u hive hive --service metastore</p></p>
<p style="padding-left: 30px;">权限问题：<br />
这里注意启动服务使用的用户，如果root用户在hdfs上没有创建文件等权限，则会影响建表等操作。这里使用hive用户（sudo -u hive）。<br />
当然首先应确保，hive用户应拥有HDFS上/hive（即hive.metastore.warehouse.dir指定目录）的创建或者读写权限。<br />
如果没有的话，可以使用HDFS的supergroup用户进行如下方式操作：<br />
shell>hadoop fs -mkdir /hive<br />
shell>hadoop fs -chown hive:hdfs /hive<br />
这样后续hive用户就具有完全的控制权限。客户端远程连接服务后，执行的权限就是服务启动所使用的用户权限。</p></p>
<p style="padding-left: 30px;">可以使用-p指定端口：<br />
shell> hive --service metastore -p
<port_num></p></p>
<p style="padding-left: 30px;">作为服务的话，最好启用后台运行，如：<br />
shell> hive --service metastore -p 9084 &amp;</p></p>
<p style="padding-left: 30px;">2.查询是否活动<br />
shell> netstat -tlnp | grep 9083<br />
tcp 0 0 0.0.0.0:9083 0.0.0.0:* LISTEN 7008/java<br />
如上有信息返回即是正常。</p></p>
<p style="padding-left: 30px;">3.关闭服务<br />
shell> kill 7008 #指定查询到的进程的pid。</p><br />
另外例如开机启动，hive-metastore服务已经整合了这个功能。</p>
<p>参考：<br />
<a href="https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin" target="_blank">https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin</a><br />
《Programming Hive》</p>
